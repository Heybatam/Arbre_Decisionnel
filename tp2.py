# -*- coding: utf-8 -*-
"""TP2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w8RCals1agaFRMZA6XX5wzxTnB03jgO6

**Partie 1**
"""

from sklearn import tree
clf = tree.DecisionTreeClassifier()

X = [[0, 0], [1, 1]]
y = [0, 1]

clf = clf.fit(X, y)

clf.predict([[2.,2.]])

clf.predict_proba([[2., 2.]])

"""**Classification des données Iris**"""

from sklearn.datasets import load_iris

iris = load_iris()
X, y = iris.data, iris.target

data = pd.DataFrame(X)
data = data.reset_index(drop = True)

data.columns = ["Sepal length","Sepal width","Petal length","Petal width"]

data.describe()

sum(iris.target == 2)

from sklearn.model_selection import train_test_split
from sklearn import tree

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state =2)

clf = tree.DecisionTreeClassifier()

clf.fit(X_train, y_train)

tree.plot_tree(clf, filled=True )

clf.predict(X_test)

clf.score(X_test, y_test)

"""Impact des paramètres depth et leaf"""

clf = tree.DecisionTreeClassifier(max_depth =3, min_samples_leaf = 20)

clf.fit(X_train, y_train)

tree.plot_tree(clf, filled = True)

"""Question : Le problème ici étant particulièrement simple, refaites une division 
apprentissage/test avec 5% des données en apprentissage et 95% test. 
Calculez le taux d’éléments mal classifiés sur l’ensemble de test. 
Faites  varier  (ou  mieux,  réalisez  une  recherche  par  grille  avec  GridSearchCV)  les 
valeurs des paramètres max_depth et min_samples_leaf pour mesurer leur impact sur 
ce score.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.95, random_state =2)

clf = tree.DecisionTreeClassifier()
clf.fit(X_train, y_train)
clf.predict(X_test)
clf.score(X_test, y_test)

clf = tree.DecisionTreeClassifier(min_samples_leaf = 5)
clf.fit(X_train, y_train)
clf.predict(X_test)
clf.score(X_test, y_test)

from sklearn.model_selection import GridSearchCV
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix

dt = tree.DecisionTreeClassifier()

parameters = {'max_depth':[2,5,10,15,20], 'min_samples_leaf':[2,5,10,15,20]}
clf = GridSearchCV(dt, parameters)
clf.fit(X_train, y_train)
grid = GridSearchCV(estimator=DecisionTreeClassifier(),
             param_grid=parameters)
sorted(clf.cv_results_.keys())

grid.fit(X_train, y_train) 
grid_predictions = grid.predict(X_test) 
print(classification_report(y_test, grid_predictions))

clf.best_params_

import numpy as np 
import matplotlib.pyplot as plt 
 
# Paramètres 
n_classes = 3 
plot_colors = "bry" # blue-red-yellow 
plot_step = 0.02 
 
# Choisir les attributs longueur et largeur des pétales 
pair = [2, 3] 
 
# On ne garde seulement les deux attributs 
X = iris.data[:, pair] 
y = iris.target 
 
def arbre_decision(X,y):
  # Apprentissage de l'arbre 
  clf = tree.DecisionTreeClassifier().fit(X, y) 
  
  # Affichage de la surface de décision 
  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1

  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 
  xx,  yy  =  np.meshgrid(np.arange(x_min,  x_max,  plot_step),  np.arange(y_min, 
  y_max, plot_step)) 
  Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) 
  Z = Z.reshape(xx.shape) 
  cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired) 
  plt.xlabel(iris.feature_names[pair[0]]) 
  plt.ylabel(iris.feature_names[pair[1]]) 
  plt.axis("tight") 
  
  # Affichage des points d'apprentissage 
  for i, color in zip(range(n_classes), plot_colors): 
      idx = np.where(y == i) 
      plt.scatter(X[idx,  0],  X[idx,  1],  c=color,  label=iris.target_names[i], 
  cmap=plt.cm.Paired) 
  plt.axis("tight") 
  plt.suptitle("Decision surface of a decision tree using paired features") 
  plt.legend() 
  plt.show()

arbre_decision(X,y)

# Choisir les attributs longueur et largeur des pétales 
pair = [0, 1] 
 
# On ne garde seulement les deux attributs 
X = iris.data[:, pair] 
y = iris.target 

arbre_decision(X,y)

# Choisir les attributs longueur et largeur des pétales 
pair = [0, 2] 
 
# On ne garde seulement les deux attributs 
X = iris.data[:, pair] 
y = iris.target 

arbre_decision(X,y)

# Choisir les attributs longueur et largeur des pétales 
pair = [0, 3] 
 
# On ne garde seulement les deux attributs 
X = iris.data[:, pair] 
y = iris.target 

arbre_decision(X,y)

# Choisir les attributs longueur et largeur des pétales 
pair = [1, 2] 
 
# On ne garde seulement les deux attributs 
X = iris.data[:, pair] 
y = iris.target 

arbre_decision(X,y)

# Choisir les attributs longueur et largeur des pétales 
pair = [1, 3] 
 
# On ne garde seulement les deux attributs
X = iris.data[:, pair] 
y = iris.target 

arbre_decision(X,y)

from sklearn import tree 
 
X = [[0, 0], [2, 2]] 
y = [0.5, 2.5] 
clf = tree.DecisionTreeRegressor() 
clf = clf.fit(X, y) 
clf.predict([[1, 1]])

import numpy as np 
import matplotlib.pyplot as plt 
 
from sklearn.tree import DecisionTreeRegressor 
 
# Créer les données d'apprentissage 
np.random.seed(0) 
X = np.sort(5 * np.random.rand(80, 1), axis=0) 
y = np.sin(X).ravel() 
fig = plt.figure(figsize=(12, 4)) 
fig.add_subplot(121) 
plt.plot(X, y) 
plt.title("Signal sinusoïdal pur") 
 
# On ajoute un bruit aléatoire tous les 5 échantillons 
y[::5] += 3 * (0.5 - np.random.rand(16)) 
fig.add_subplot(122) 
plt.plot(X, y) 
plt.title("Signal sinusoïdal bruité")

def ad_reg(X,y,nb):  
  # Apprendre le modèle 
  reg = DecisionTreeRegressor(max_depth=nb) 
  reg.fit(X, y) 
  
  # Prédiction sur la même plage de valeurs 
  X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis] 
  y_pred = reg.predict(X_test) 
  
  # Affichage des résultats 
  plt.figure() 
  plt.scatter(X, y, c="darkorange", label="Exemples d'apprentissage") 
  plt.plot(X_test, y_pred, color="cornflowerblue", label="Prédiction", 
  linewidth=2) 
  plt.xlabel("x") 
  plt.ylabel("y") 
  plt.title("Régression par un arbre de décision") 
  plt.legend() 
  plt.show()

"""Question : 
Changer la valeur du paramètre max_depth. Que se passe-t-il si on prend une valeur 
trop  grande  ?  Trop  petite  ?  Changer  le  taux  d’éléments  affectés  par  le  bruit 
(le y[::5]). Quand tous les éléments sont affectés par le bruit, faut-il préférer une 
valeur élevée ou faible pour max_depth ? 
 
Question : 
Pour approfondir, chargez la base de données Diabètes du 
module sklearn.datasets et faire une partition aléatoire en partie apprentissage et 
partie  test  (70%  apprentissage,  30%  test).  Construire  un  modèle  d’arbre  de 
regression sur cette base. Calculer l’erreur quadratique moyenne sur l’ensemble 
de test. Faire un grid search pour trouver la valeur du paramètre max_depth qui 
minimise cette erreur.
"""

ad_reg(X,y,15)

# Créer les données d'apprentissage 
np.random.seed(0) 
X = np.sort(5 * np.random.rand(80,1), axis=0) 
y = np.sin(X).ravel() 
fig = plt.figure(figsize=(12, 4)) 
fig.add_subplot(121) 
plt.plot(X, y) 
plt.title("Signal sinusoïdal pur") 
 
# On ajoute un bruit aléatoire tous les 5 échantillons 
y[::1] += 3 * (0.5 - np.random.rand(80)) 
fig.add_subplot(122) 
plt.plot(X, y) 
plt.title("Signal sinusoïdal bruité")

ad_reg(X,y,10)

ad_reg(X,y,30)

ad_reg(X,y,3)

ad_reg(X,y,5)

from sklearn.datasets import load_diabetes
import numpy as np

X,y = load_diabetes(return_X_y=True)

np.isnan(X).sum()

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 2)

print("x_train shape: ", X_train.shape)
print("y_train shape: ", y_train.shape)
print("x_test shape: ", X_test.shape)
print("y_test shape: ", y_test.shape)

reg = DecisionTreeRegressor(max_depth = 3) 
reg.fit(X_train, y_train) 

y_pred = reg.predict(X_test)

from sklearn.metrics import mean_squared_error

print('mse (sklearn): ', mean_squared_error(y_test,y_pred))

dt = tree.DecisionTreeClassifier()


parameters = {'max_depth':[2,5,10,15,20,50,100]}
clf=GridSearchCV(dt,param_grid=parameters,scoring='neg_root_mean_squared_error',cv=3,verbose=3)
clf.fit(X_train, y_train)
grid = GridSearchCV(estimator=DecisionTreeClassifier(),
             param_grid=parameters)
sorted(clf.cv_results_.keys())

grid.fit(X_train, y_train) 
grid_predictions = grid.predict(X_test)

clf.best_params_

clf.best_score_

